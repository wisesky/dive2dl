{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'1.5.1'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'10.2'"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7605"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11593abd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "# torch.cuda.manual_seed_all(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES = 0,1 python train.py\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图的随机性配置\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图 确定性 配置\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# nvidia-smi --gpu-reset -i [gpu_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor.type()\n",
    "# tensor.size()\n",
    "# tensor.dim()\n",
    "\n",
    "# tensor = tensor.cuda()\n",
    "# tensor = tensor.cpu()\n",
    "# tensor = tensor.float()\n",
    "# tensor = tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tensor -> np\n",
    "ndarray = tensor.numpy()\n",
    "# np -> tensor\n",
    "tensor = torch.from_numpy(ndarray).float()\n",
    "tensor = torch.from_numpy(ndarray.copy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor -> image\n",
    "image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
    "# or\n",
    "image = torchvision.transforms.functional.to_pil_image(tensor)\n",
    "# image -> tensor\n",
    "tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2, 0, 1).float() / 255\n",
    "tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndarray -> image\n",
    "image = PIL.Image.fromarray(ndarray.astype(np.uint8))\n",
    "# image -> ndarray\n",
    "ndarray = np.asarray(PIL.Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor -> element\n",
    "value = tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "tensor = torch.reshape(tensor, shape)\n",
    "# shuffle \n",
    "# 1st dim\n",
    "tensor = torch[torch.randperm(tensor.size(0))]\n",
    "#  水平翻转 [ : :-1]\n",
    "tensor = tensor[ : , : , : , torch.arange(tensor.size(3)-1, -1, -1).long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 different copy\n",
    "# operation          New/Shared Memory.         still in computation graph\n",
    "tensor.clone()          New                        Yes\n",
    "tensor.detach()         Shared                     No\n",
    "tensor.detach.clone()   New                        No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concact\n",
    "tesnor = torch.cat(list_of_tensors, dim=0) # pd.DataFrame.concat\n",
    "tensor = torch.stack(list_of_tensors, dim=0) # new dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot code\n",
    "N = tensor.size(0)\n",
    "one_hot = torch.zeros(N, num_classes).long()\n",
    "one_hot.scatter(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.Tensor([1,1,1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elements == 0\n",
    "torch.nonezero(tensor) # indexs of nonzero\n",
    "torch.nonzero(tensor == 0) # indexs of zero\n",
    "torch.nonzero(tensor).size(0) # nums of nonzero\n",
    "torch.nonzero(tensor==0).size(0) # nums of zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expend tensor 64 * 512 -> 64 * 512 * 7 * 7\n",
    "tensor = torch.ones((64, 512))\n",
    "torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication\n",
    "# (m*n ) * (n*p) -> (m*p)\n",
    "res = torch.mm(tensor1, tensor2)\n",
    "# batch mm\n",
    "res = torch.bmm(tensor1, tensor2)\n",
    "# element-wise\n",
    "res = tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0591, 0.1834],\n",
       "        [0.4650, 0.9579],\n",
       "        [0.6641, 0.6408]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand((3,2))\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.ones((2,2))\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[ : ,None, : ].shape == x1.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2459, 1.2459],\n",
       "        [0.5366, 0.5366],\n",
       "        [0.4918, 0.4918]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算x1 x2 两两之间的欧式距离: 利用广播机制\n",
    "dist = torch.sqrt(\n",
    "            torch.sum((x1.unsqueeze(1) - x2) ** 2,\n",
    "            dim=2\n",
    "    )\n",
    ")\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define conv\n",
    "conv = torch.nn.Conv2d(in_channels, out_channels,\n",
    "                      kernel_size, stride, bias\n",
    "                      )\n",
    "# GAP（Global average pooling）层\n",
    "gap = torch.nn.AdaptiveAvgPool2d(output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双线性汇合（bilinear pooling）\n",
    "X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W\n",
    "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling\n",
    "assert X.size() == (N, D, D)\n",
    "X = torch.reshape(X, (N, D * D))\n",
    "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization\n",
    "X = torch.nn.functional.normalize(X)                  # L2 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多卡同步BN（Batch normalization）\n",
    "\n",
    "# 当使用torch.nn.DataParallel将代码运行在多张GPU卡上时，\n",
    "# PyTorch的BN层默认操作是各卡上数据独立地计算均值和标准差，\n",
    "# 同步BN使用所有卡上的数据一起计算BN层的均值和标准差，\n",
    "# 缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，\n",
    "# 是在目标检测等任务中一个有效的提升性能的技巧。\n",
    "sync_bn = torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True, \n",
    "                                 track_running_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertBNtoSyncBN(module, process_group=None):\n",
    "    '''Recursively replace all BN layers to SyncBN layer.\n",
    "\n",
    "    Args:\n",
    "        module[torch.nn.Module]. Network\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, \n",
    "                                         module.affine, module.track_running_stats, process_group)\n",
    "        sync_bn.running_mean = module.running_mean\n",
    "        sync_bn.running_var = module.running_var\n",
    "        if module.affine:\n",
    "            sync_bn.weight = module.weight.clone().detach()\n",
    "            sync_bn.bias = module.bias.clone().detach()\n",
    "        return sync_bn\n",
    "    else:\n",
    "        for name, child_module in module.named_children():\n",
    "            setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group))\n",
    "        return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类似BN滑动平均\n",
    "class BN(torch.nn.Module)\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        ...\n",
    "        self.running_mean += momentum * (current - self.running_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计 参数量\n",
    "num_parameters = sum(\n",
    "        torch.numel(parameter) for parameter in model.parameters()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary 遍历 model layers 间 矩阵大小的变化\n",
    "from torchsummary import summary # pip install torchsummary\n",
    "summary(your_model, input_size(channels, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "summary(model, (1, 28, 28)) # as kernerl_size = 5 默认步长 stride=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common practice for initialization\n",
    "for layer in model.modulers():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, model='fan_out',\n",
    "                                     nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "            \n",
    "# initialization with given tensor\n",
    "layer.weight = torch.nn.Parameter(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-train model\n",
    "model.load_state_dict(torch.load('model-path'), strict=False)\n",
    "# cpu\n",
    "model.load_state_dict(torch.load('model-path'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning \n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 100)\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, \n",
    "                            momentum=0.9, weight_decay=1e-4\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning with different lr\n",
    "parameters = [{'params': conv_parameters, 'lr': 1e-3}, \n",
    "              {'params': model.fc.parameters()}]\n",
    "optimizer = torch.optim.SGD(parameters, lr=1e-2, \n",
    "                            momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "for t in epoch(80):\n",
    "    for images, labels in tqdm.tqdm(train_loader, desc='Epoch %3d' % (t + 1)):\n",
    "#         images, labels = images.cuda(), labels.cuda()\n",
    "        scores = model(images)\n",
    "        loss = loss_function(scores, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标记平滑（label smoothing\n",
    "# 略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixup\n",
    "# 略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 Reg\n",
    "l1_regularization = torch.nn.L1Loss(reduction='sum')\n",
    "# or \n",
    "# loss = nn.CrossEntropyLoss()\n",
    "for param in model.parameters():\n",
    "    loss += lambda_ * torch.sum(torch.abs(param))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对某些参数不参与 weight decay\n",
    "bias_list = (param for name, param in model.named_parameters() \n",
    "            if name[-4: ] == 'bias')\n",
    "others_list = (param for name, param in model.named_parameters() \n",
    "            if name[-4: ] != 'bias')\n",
    "parameters = [{'parameters': bias_list, 'weight_decay': 0},\n",
    "             {'parameters': others_list}\n",
    "             ]\n",
    "optimizer = torch.optim.SGD(paramters, lr=1e-2, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度裁剪（gradient clipping）\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "score = model(images)\n",
    "prediction = torch.argmax(score, dim=1)\n",
    "num_correct = torch.sum(prediction == labels).item()\n",
    "acc = num_correct / labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型可视化\n",
    "# visdom\n",
    "# or\n",
    "# tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练过程中的learning rate\n",
    "# global lr\n",
    "lr = next(iter(optimizer.param_groups))['lr']\n",
    "# mutilple lr\n",
    "all_lr = []\n",
    "for param_group in optimizer.param_groups:\n",
    "    all_lr.append(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整lr\n",
    "scheluder = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max')\n",
    "\n",
    "for t in range(0,90):\n",
    "    train...\n",
    "    scheduler.step(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型断点: stat_dict\n",
    "is_best = current_acc > best_acc\n",
    "best_acc = max(best_acc, current_acc)\n",
    "checkpoint = {\n",
    "    'best_acc':best_acc,\n",
    "    'epoch': t+1,\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "model_path = os.path.join('model', 'checkpoint.pt.tar')\n",
    "torch.save(checkpoint, 'checkpoin.path.tar')\n",
    "if is_best:\n",
    "    shutil.copy('checkpoin.pt.tar', model_path)\n",
    "\n",
    "# load\n",
    "if resume:\n",
    "    model_path = os.path.join('model', 'checkpoint.pt.tar')\n",
    "    assert os.path.isfile(model_path)\n",
    "    checkpoint = torch.load(mdoel_path)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('Load Checkpoin at Epoch %d' % (start_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型: pickle\n",
    "torch.save(model, PATH)\n",
    "# load\n",
    "model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0591, 0.1834],\n",
       "        [0.4650, 0.9579],\n",
       "        [0.6641, 0.6408]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7572, -0.6329],\n",
       "        [-0.9697, -0.4768],\n",
       "        [-0.6816, -0.7049]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0609, 1.2013],\n",
       "        [1.5921, 2.6063],\n",
       "        [1.9427, 1.8980]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2621, 4.1983, 3.8407])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.exp().sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8163, 1.4347, 1.3457])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8163],\n",
       "        [1.4347],\n",
       "        [1.3457]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.exp().sum(-1).log().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.CrossEntropyLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}